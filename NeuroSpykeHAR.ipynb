{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c251ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beefff8",
   "metadata": {},
   "source": [
    "# Download and prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46af086",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_paths = [\n",
    "    './datasets',\n",
    "]\n",
    "\n",
    "# constants for each dataset\n",
    "csi_per_second   =   150\n",
    "first_subcarrier = -1024\n",
    "last_subcarrier  =  1023\n",
    "\n",
    "# csi per second after downsampling\n",
    "new_csi_per_second = 30\n",
    "\n",
    "# seconds in file\n",
    "seconds = 80\n",
    "\n",
    "# considered time window in seconds\n",
    "time_window = 3\n",
    "\n",
    "\n",
    "actions = [('A','Walk'), ('B', 'Run'), ('C', 'Jump'), ('D', 'Sitting'), \n",
    "           ('E', 'Empty Room'), ('F', 'Stand'),('G', 'Wave hands'),  ('H', 'Clapping'),\n",
    "           ('I', 'Lay'), ('J', 'Wiping'), ('K', 'Squat'), ('L', 'Stretching')] \n",
    "downsampling_modes = ['mean', 'median', 'min', 'max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e0c1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-04 12:41:45--  https://zenodo.org/records/7751897/files/S4.zip\n",
      "Resolving zenodo.org (zenodo.org)... 188.184.103.159, 188.185.79.172, 188.184.98.238, ...\n",
      "Connecting to zenodo.org (zenodo.org)|188.184.103.159|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11019742449 (10G) [application/octet-stream]\n",
      "Saving to: ‘S4.zip’\n",
      "\n",
      "S4.zip                3%[                    ] 324.50M  50.0MB/s    eta 3m 57s "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S4.zip              100%[===================>]  10.26G  48.0MB/s    in 3m 41s  \n",
      "\n",
      "2024-07-04 12:45:25 (47.7 MB/s) - ‘S4.zip’ saved [11019742449/11019742449]\n",
      "\n",
      "Archive:  S4.zip\n",
      "   creating: S4/\n",
      "  inflating: S4/LICENSE              \n",
      "  inflating: S4/README               \n",
      "  inflating: S4/S4a_A.mat            \n",
      "  inflating: S4/S4a_B.mat            \n",
      "  inflating: S4/S4a_C.mat            \n",
      "  inflating: S4/S4a_D.mat            \n",
      "  inflating: S4/S4a_E.mat            \n",
      "  inflating: S4/S4a_F.mat            \n",
      "  inflating: S4/S4a_G.mat            \n",
      "  inflating: S4/S4a_H.mat            \n",
      "  inflating: S4/S4a_I.mat            \n",
      "  inflating: S4/S4a_J.mat            \n",
      "  inflating: S4/S4a_K.mat            \n",
      "  inflating: S4/S4a_L.mat            \n",
      "  inflating: S4/S4b_A.mat            \n",
      "  inflating: S4/S4b_B.mat            \n",
      "  inflating: S4/S4b_C.mat            \n",
      "  inflating: S4/S4b_D.mat            \n",
      "  inflating: S4/S4b_E.mat            \n",
      "  inflating: S4/S4b_F.mat            \n",
      "  inflating: S4/S4b_G.mat            \n",
      "  inflating: S4/S4b_H.mat            \n",
      "  inflating: S4/S4b_I.mat            \n",
      "  inflating: S4/S4b_J.mat            \n",
      "  inflating: S4/S4b_K.mat            \n",
      "  inflating: S4/S4b_L.mat            \n",
      "  inflating: S4/S4c_A.mat            \n",
      "  inflating: S4/S4c_B.mat            \n",
      "  inflating: S4/S4c_C.mat            \n",
      "  inflating: S4/S4c_D.mat            \n",
      "  inflating: S4/S4c_E.mat            \n",
      "  inflating: S4/S4c_F.mat            \n",
      "  inflating: S4/S4c_G.mat            \n",
      "  inflating: S4/S4c_H.mat            \n",
      "  inflating: S4/S4c_I.mat            \n",
      "  inflating: S4/S4c_J.mat            \n",
      "  inflating: S4/S4c_K.mat            \n",
      "  inflating: S4/S4c_L.mat            \n",
      "renamed 'S4/LICENSE' -> 'datasets/dataset/LICENSE'\n",
      "renamed 'S4/README' -> 'datasets/dataset/README'\n",
      "renamed 'S4/S4a_A.mat' -> 'datasets/dataset/S4a_A.mat'\n",
      "renamed 'S4/S4a_B.mat' -> 'datasets/dataset/S4a_B.mat'\n",
      "renamed 'S4/S4a_C.mat' -> 'datasets/dataset/S4a_C.mat'\n",
      "renamed 'S4/S4a_D.mat' -> 'datasets/dataset/S4a_D.mat'\n",
      "renamed 'S4/S4a_E.mat' -> 'datasets/dataset/S4a_E.mat'\n",
      "renamed 'S4/S4a_F.mat' -> 'datasets/dataset/S4a_F.mat'\n",
      "renamed 'S4/S4a_G.mat' -> 'datasets/dataset/S4a_G.mat'\n",
      "renamed 'S4/S4a_H.mat' -> 'datasets/dataset/S4a_H.mat'\n",
      "renamed 'S4/S4a_I.mat' -> 'datasets/dataset/S4a_I.mat'\n",
      "renamed 'S4/S4a_J.mat' -> 'datasets/dataset/S4a_J.mat'\n",
      "renamed 'S4/S4a_K.mat' -> 'datasets/dataset/S4a_K.mat'\n",
      "renamed 'S4/S4a_L.mat' -> 'datasets/dataset/S4a_L.mat'\n",
      "renamed 'S4/S4b_A.mat' -> 'datasets/dataset/S4b_A.mat'\n",
      "renamed 'S4/S4b_B.mat' -> 'datasets/dataset/S4b_B.mat'\n",
      "renamed 'S4/S4b_C.mat' -> 'datasets/dataset/S4b_C.mat'\n",
      "renamed 'S4/S4b_D.mat' -> 'datasets/dataset/S4b_D.mat'\n",
      "renamed 'S4/S4b_E.mat' -> 'datasets/dataset/S4b_E.mat'\n",
      "renamed 'S4/S4b_F.mat' -> 'datasets/dataset/S4b_F.mat'\n",
      "renamed 'S4/S4b_G.mat' -> 'datasets/dataset/S4b_G.mat'\n",
      "renamed 'S4/S4b_H.mat' -> 'datasets/dataset/S4b_H.mat'\n",
      "renamed 'S4/S4b_I.mat' -> 'datasets/dataset/S4b_I.mat'\n",
      "renamed 'S4/S4b_J.mat' -> 'datasets/dataset/S4b_J.mat'\n",
      "renamed 'S4/S4b_K.mat' -> 'datasets/dataset/S4b_K.mat'\n",
      "renamed 'S4/S4b_L.mat' -> 'datasets/dataset/S4b_L.mat'\n",
      "renamed 'S4/S4c_A.mat' -> 'datasets/dataset/S4c_A.mat'\n",
      "renamed 'S4/S4c_B.mat' -> 'datasets/dataset/S4c_B.mat'\n",
      "renamed 'S4/S4c_C.mat' -> 'datasets/dataset/S4c_C.mat'\n",
      "renamed 'S4/S4c_D.mat' -> 'datasets/dataset/S4c_D.mat'\n",
      "renamed 'S4/S4c_E.mat' -> 'datasets/dataset/S4c_E.mat'\n",
      "renamed 'S4/S4c_F.mat' -> 'datasets/dataset/S4c_F.mat'\n",
      "renamed 'S4/S4c_G.mat' -> 'datasets/dataset/S4c_G.mat'\n",
      "renamed 'S4/S4c_H.mat' -> 'datasets/dataset/S4c_H.mat'\n",
      "renamed 'S4/S4c_I.mat' -> 'datasets/dataset/S4c_I.mat'\n",
      "renamed 'S4/S4c_J.mat' -> 'datasets/dataset/S4c_J.mat'\n",
      "renamed 'S4/S4c_K.mat' -> 'datasets/dataset/S4c_K.mat'\n",
      "renamed 'S4/S4c_L.mat' -> 'datasets/dataset/S4c_L.mat'\n"
     ]
    }
   ],
   "source": [
    "!wget https://zenodo.org/records/7751897/files/S1.zip\n",
    "!unzip S1.zip\n",
    "!mv -v S1/* datasets/dataset/\n",
    "!rm S1.zip\n",
    "!rm -r S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30638ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved mean Walk\n",
      "saved median Walk\n",
      "saved max Walk\n",
      "saved min Walk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved mean Run\n",
      "saved median Run\n",
      "saved max Run\n",
      "saved min Run\n",
      "saved mean Jump\n",
      "saved median Jump\n",
      "saved max Jump\n",
      "saved min Jump\n",
      "saved mean Sitting\n",
      "saved median Sitting\n",
      "saved max Sitting\n",
      "saved min Sitting\n",
      "saved mean Empty Room\n",
      "saved median Empty Room\n",
      "saved max Empty Room\n",
      "saved min Empty Room\n",
      "saved mean Stand\n",
      "saved median Stand\n",
      "saved max Stand\n",
      "saved min Stand\n",
      "saved mean Wave hands\n",
      "saved median Wave hands\n",
      "saved max Wave hands\n",
      "saved min Wave hands\n",
      "saved mean Clapping\n",
      "saved median Clapping\n",
      "saved max Clapping\n",
      "saved min Clapping\n",
      "saved mean Lay\n",
      "saved median Lay\n",
      "saved max Lay\n",
      "saved min Lay\n",
      "saved mean Wiping\n",
      "saved median Wiping\n",
      "saved max Wiping\n",
      "saved min Wiping\n",
      "saved mean Squat\n",
      "saved median Squat\n",
      "saved max Squat\n",
      "saved min Squat\n",
      "saved mean Stretching\n",
      "saved median Stretching\n",
      "saved max Stretching\n",
      "saved min Stretching\n"
     ]
    }
   ],
   "source": [
    "# create files with downsampled csi\n",
    "def downsample(candidate_paths, csi_per_second, new_csi_per_second, actions):\n",
    "    for action in actions:\n",
    "        filename = f'S4a_{action[0]}'\n",
    "        # Read CSI from the first file found among the candidates\n",
    "        for path in candidate_paths:\n",
    "          full_path_name = f'{path}/dataset/{filename}.mat'\n",
    "          if os.path.exists(full_path_name):\n",
    "            csi = scipy.io.loadmat(full_path_name)['csi']\n",
    "          else:\n",
    "            print(f'File {full_path_name} not found')\n",
    "        \n",
    "        csi = np.abs(csi)\n",
    "        data_reshaped = csi.reshape(-1, int(csi_per_second/new_csi_per_second), 2048, 4) #[2400, 5, 2048, 4]\n",
    "\n",
    "        \n",
    "        # Aggregation functions\n",
    "        csi_mean = data_reshaped.mean(axis=1) #[2400,2048,4]\n",
    "        csi_median = np.median(data_reshaped, axis=1)\n",
    "        csi_max = data_reshaped.max(axis=1)\n",
    "        csi_min = data_reshaped.min(axis=1)\n",
    "\n",
    "        # Save the new CSI data\n",
    "        with open(f'{path}/mean_dataset_abs/{filename}.pkl', 'wb') as f:\n",
    "            pickle.dump(csi_mean, f)\n",
    "            print(f'saved mean {action[1]}')\n",
    "\n",
    "        with open(f'{path}/median_dataset_abs/{filename}.pkl', 'wb') as f:\n",
    "            pickle.dump(csi_median, f)\n",
    "            print(f'saved median {action[1]}')\n",
    "\n",
    "        with open(f'{path}/max_dataset_abs/{filename}.pkl', 'wb') as f:\n",
    "            pickle.dump(csi_max, f)\n",
    "            print(f'saved max {action[1]}')\n",
    "        \n",
    "        with open(f'{path}/min_dataset_abs/{filename}.pkl', 'wb') as f:\n",
    "            pickle.dump(csi_min, f)\n",
    "            print(f'saved min {action[1]}')\n",
    "\n",
    "downsample(candidate_paths, csi_per_second, new_csi_per_second, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1b1018",
   "metadata": {},
   "source": [
    "# Baseline SNN vs CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a296fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['Walk', 'Run', 'Jump', 'Wave hands', 'Clapping', 'Wiping', 'Squat']\n",
    "from SNN.neural import main as train\n",
    "from SNN.metrics import bayesianHypothesisTesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e1c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmSNN, cmCNN = train()\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cmSNN, display_labels=LABELS)\n",
    "cmdisp = disp.plot(cmap=\"cividis\")\n",
    "plt.setp(cmdisp.ax_.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.setp(cmdisp.ax_.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "cmdisp.figure_.set_size_inches(12, 12)\n",
    "cmdisp.figure_.savefig(\"SNN/results/neuralOnly/ConMatSNN1s.png\", bbox_inches='tight')\n",
    "\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cmCNN, display_labels=LABELS)\n",
    "cmdisp = disp.plot(cmap=\"cividis\")\n",
    "plt.setp(cmdisp.ax_.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.setp(cmdisp.ax_.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "cmdisp.figure_.set_size_inches(12, 12)\n",
    "cmdisp.figure_.savefig(\"SNN/results/neuralOnly/ConfMatCnn1s.png\", bbox_inches='tight')\n",
    "\n",
    "print(f'Accuracy SNN: {np.trace(cmSNN)/np.sum(cmSNN)}')\n",
    "print(f'Accuracy CNN: {np.trace(cmCNN)/np.sum(cmCNN)}')\n",
    "\n",
    "bayesianHypothesisTesting(cmSNN, cmCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d209c364",
   "metadata": {},
   "source": [
    "# Neurosymbolic SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dca59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SNN.results import main as neuroSpykeHar\n",
    "from SNN.results import prepare_data\n",
    "from SNN.deepprobhar import main as deepProbHar\n",
    "from SNN.metrics import bayesianHypothesisTesting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e2c2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, loader = prepare_data()\n",
    "\n",
    "cmSNN = neuroSpykeHar()\n",
    "cmVAE = deepProbHar()\n",
    "\n",
    "\n",
    "# Save the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cmSNN, display_labels=LABELS)\n",
    "cmdisp = disp.plot(cmap=\"cividis\")\n",
    "plt.setp(cmdisp.ax_.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.setp(cmdisp.ax_.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "cmdisp.figure_.set_size_inches(12, 12)\n",
    "cmdisp.figure_.savefig(f\"SNN/results/neuroSymbolic/ConfMatSNN.png\", bbox_inches='tight')\n",
    "\n",
    "\t# Save the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cmVAE, display_labels=LABELS)\n",
    "cmdisp = disp.plot(cmap=\"cividis\")\n",
    "plt.setp(cmdisp.ax_.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.setp(cmdisp.ax_.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "cmdisp.figure_.set_size_inches(12, 12)\n",
    "cmdisp.figure_.savefig(f\"SNN/results/neuroSymbolic/ConfMatVAE.png\", bbox_inches='tight')\n",
    "\n",
    "print(f'Accuracy SNN: {np.trace(cmSNN)/np.sum(cmSNN)}')\n",
    "print(f'Accuracy CNN: {np.trace(cmVAE)/np.sum(cmVAE)}')\n",
    "\n",
    "bayesianHypothesisTesting(cmSNN, cmVAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9244253",
   "metadata": {},
   "source": [
    "# Temporal Neurosymbolic SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e3d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SNN.nsTrain import main as nsTrain\n",
    "\n",
    "nsTrain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
